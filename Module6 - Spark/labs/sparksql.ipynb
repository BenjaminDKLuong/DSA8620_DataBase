{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:red;font-weight:bold;background:yellow;text-align:center;padding:10px;border:solid\">\n",
    "    <h1>RUN IN EMR CLUSTER ONLY</h1>\n",
    "    If the URL of the current page does not begin with \"ec2\", then do **NOT** proceed!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSQL\n",
    "In this lab, we will look at using Spark with SQL to ingest and analyze datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = !hostname\n",
    "if \"dsa\" in name[0]:\n",
    "    raise RuntimeError(\"Only run this notebook in the EMR Cluster!\")\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName(\"pyspark-lab\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "\n",
    "We will use Amazon Review data. \n",
    "\n",
    "**<span style=\"background:yellow\">Please note, this will take a few minutes to stage into memory on the cluster.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# To use Spark SQL we create a SQLContext from SparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Location of the dataset on HDFS\n",
    "DATASET = '/datasets/amazon_reviews.json'\n",
    "\n",
    "# Load a table with a JSON format reader and get the first 1000 rows\n",
    "df = sqlContext.read.json(DATASET).limit(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(helpfulness_count=7, helpfulness_score=7, price=-1.0, product_id='B000179R3I', profile_name='Jeanmarie Kabala \"JP Kabala\"', score=4.0, summary='Periwinkle Dartmouth Blazer', text='I own the Austin Reed dartmouth blazer in every color in which they make it-- it is a staple of my business wardrobe. Well made, quality fabric, nicely tailored, classic lines, appropriate for a professional woman. (something that can be hard to find at times) It should be noted, however, that the periwinkle and raspberry colors are lovely, but the fabric and buttons are slightly different than the \"classic\" colors(lighter) and the linings and interfacings are not as substantial as the brown, navy, camel, red and ivory. It\\'s still a good value, particularly as these are colors appropriate to warmer seasons and climates, but I was a bit surprised.', time=1182816000, title='Amazon.com', user_id='A3Q0VJTUO4EZ56')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL DataFrame vs. Pandas DataFrame\n",
    "The DataFrame returned by SparkSQL is _NOT_ the same as a Pandas DataFrame. You can find the documentation what operations can be performed on a SparkSQL Dataframe [here](http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame).\n",
    "\n",
    "To convert a SparkSQL DataFrame to a Pandas dataframe, you can do this:\n",
    "```python\n",
    "pandas_dataframe = spark_dataframe.toPandas()\n",
    "```\n",
    "\n",
    "## NoSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SparkSQL DataFrame can be accessed similarly to a NoSQL database.\n",
    "Note, these are similar to the capabilities of the Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viewing A Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|score|\n",
      "+-----+\n",
      "|  4.0|\n",
      "|  5.0|\n",
      "|  3.0|\n",
      "|  4.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  4.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "|  5.0|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"score\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering Data**\n",
    "Note the chain of operations above.\n",
    "If we decompose the chain into steps, we see that operations like filter and select give us new SparkSQL DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.filter(df[\"score\"] < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-----+----------+--------------------+-----+--------------------+--------------------+----------+--------------------+--------------+\n",
      "|helpfulness_count|helpfulness_score|price|product_id|        profile_name|score|             summary|                text|      time|               title|       user_id|\n",
      "+-----------------+-----------------+-----+----------+--------------------+-----+--------------------+--------------------+----------+--------------------+--------------+\n",
      "|               11|                7|10.95|0595344550|         Book Reader|  1.0|            not good|I bought this boo...|1117065600|Whispers of the W...|A3Q12RK71N74LB|\n",
      "|                2|                1|10.95|0595344550|LoveToRead \"Actua...|  1.0|        Buyer beware|This is a self-pu...|1119225600|Whispers of the W...| AUR0VA5H0C66C|\n",
      "|                0|                0|10.95|0595344550|        C. Robertson|  1.0|          The Worst!|A complete waste ...|1119916800|Whispers of the W...| A1P2KGE2Z8RTA|\n",
      "|                5|                5|10.95|0595344550|                  PW|  1.0|           Oh please|I guess you have ...|1115856000|Whispers of the W...|A3OS2QHEH495TD|\n",
      "|                4|                4|10.95|0595344550|              N. Ray|  1.0|Awful beyond belief!|I feel I have to ...|1119571200|Whispers of the W...|A3S5YQQWBO0LGI|\n",
      "|                7|                6|10.95|0595344550|    denpq \"A READER\"|  1.0|You've got to han...|I purchased this ...|1119830400|Whispers of the W...| A9L6GHJC42RRC|\n",
      "|                7|                6|10.95|0595344550|  Fran \"Avid reader\"|  1.0|You've got to be ...|It has been years...|1118275200|Whispers of the W...|A3T591DTKPYCVW|\n",
      "|                2|                2|10.95|0595344550|          Bronx Girl|  1.0|Don't try to fool...|It's glaringly ob...|1125273600|Whispers of the W...|A1XNI3654I4ME2|\n",
      "|                9|                6|10.95|0595344550|travelling librarian|  1.0| awful beyond belief|I can't remember ...|1119312000|Whispers of the W...|A3OZDTEEAF8GS9|\n",
      "|                1|                1|46.34|B000278ADA|              dgodoy|  2.0|sizes recomended ...|sizes are much sm...|1287014400|Jobst Ultrasheer ...| AUIZ1GNBTG5OB|\n",
      "|                3|                2|46.34|B000278ADA|Stephen Molsee \"A...|  1.0|     mens ultrasheer|This model may be...|1206748800|Jobst Ultrasheer ...|A15J55UWZ8JLJM|\n",
      "|                3|                3|12.95|B001GE2CDM|C. M. Carroll \"JA...|  1.0|Another Abysmal D...|Rather than scrat...|1318118400|An Occurence At O...|A3MJIXDIQT5S16|\n",
      "|                1|                1| -1.0|B0000630MQ|       Yisheng Zhang|  2.0|Problem with char...|I have had the ch...|1127088000|Kodak Max K2000 B...|A3P56Q3XEGTBNY|\n",
      "|                0|                0| -1.0|B0000630MQ|         Dave \"Dave\"|  2.0|Works, but not as...|I bought one of t...|1222300800|Kodak Max K2000 B...| AI6FTXD65U3ZH|\n",
      "|                0|                0| -1.0|B0000630MQ|             unknown|  1.0|        Disappointed|I read the review...|1059004800|Kodak Max K2000 B...|       unknown|\n",
      "|                3|                1| -1.0|B0000630MQ|Bronco Nagursky \"...|  1.0|Batteries died wi...|I bought this cha...|1103328000|Kodak Max K2000 B...| A4V0KWQSGOTSA|\n",
      "|                0|                0| -1.0|0854968350|    Alyssa A. Lappen|  2.0|             Oh dear|I was excited to ...|1109808000|Muslim Women's Ch...| ATDE9JYCPI0L1|\n",
      "|               10|                8|17.95|0918973031|     David I. Salter|  2.0|Thoroughly Confusing|I purchased this ...|1207353600|Dramatica for Scr...|A2JCSLVBZ1BZ46|\n",
      "|                6|                6| -1.0|B0000630MI|             unknown|  2.0|It started out fi...|I've had this for...|1057190400|JVC HR-XVC1U DVD-...|       unknown|\n",
      "|                2|                2| -1.0|B0000630MI|       RatPacker2000|  2.0|DVD Player crappe...|I also began havi...|1125878400|JVC HR-XVC1U DVD-...|A27YO2HVUD6G6C|\n",
      "+-----------------+-----------------+-----+----------+--------------------+-----+--------------------+--------------------+----------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Grouping Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|score|count|\n",
      "+-----+-----+\n",
      "|  4.0|  183|\n",
      "|  5.0|  636|\n",
      "|  3.0|   65|\n",
      "|  1.0|   71|\n",
      "|  2.0|   45|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"score\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SQL with SparkSQL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use SQL with Spark as well, which is very helpful for extracting information from the data we've found.\n",
    "\n",
    "\n",
    "First, we must register the temporary table with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run any SQL query, and get a SparkSQL DataFrame back!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** What is the average price of products with a score of 4 or greater? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(price)|\n",
      "+-----------------+\n",
      "|6.041538461538451|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT AVG(price) FROM review WHERE score >= 4\"\n",
    "sqlContext.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** What is the overall average helpfulness score? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|avg(helpfulness_score)|\n",
      "+----------------------+\n",
      "|                 4.973|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT AVG(helpfulness_score) FROM review\"\n",
    "sqlContext.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** What is the average score of all products cheaper than $20? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        avg(score)|\n",
      "+------------------+\n",
      "|4.2735527809307605|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT AVG(score) FROM review WHERE price < 20\"\n",
    "sqlContext.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** How many titles contain the phrase \"Amazon\"? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      16|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM review WHERE title LIKE '%Amazon%'\"\n",
    "sqlContext.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background:yellow\">Your Turn</span> ###\n",
    "Use SparkSQL to answer the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1: How many `text`s contain the phrases \"nice\" or \"good\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     218|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM review WHERE (text LIKE '%good%' OR text LIKE '%nice%')\"\n",
    "sqlContext.sql(query).show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2: What is the average price of products that have a score less than 3 and a helpfulness score less than 5?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|      avg(price)|\n",
      "+----------------+\n",
      "|7.79823529411765|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT AVG(price) FROM review WHERE ((score < 3) AND (helpfulness_score <5))\"\n",
    "sqlContext.sql(query).show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3: How many products have product IDs beginning with the letter `B`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|product_id|\n",
      "+----------+\n",
      "|B000179R3I|\n",
      "|B000GKXY34|\n",
      "|B000GKXY34|\n",
      "|B00002066I|\n",
      "|B00002066I|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT product_id FROM review WHERE (product_id LIKE 'B%') LIMIT 5\"\n",
    "sqlContext.sql(query).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     742|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM review WHERE (product_id LIKE 'B%')\"\n",
    "sqlContext.sql(query).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
